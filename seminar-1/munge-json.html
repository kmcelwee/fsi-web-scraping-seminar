<h1 id="data-cleaning">Data Cleaning</h1>

<p>The most important (and least glamorous) part of working with data is creating
a data pipeline. This data pipeline implements a cleaning process where you transform
the data you find in the wild into a dataset that you can use to answer your
research question. Data cleaning includes‚Ä¶</p>

<ul>
  <li>Joinining multiple datasets together.</li>
  <li>Updating values to adhere to a standard.
    <ul>
      <li>e.g. survey data may ask for class year and you‚Äôll get ‚Äú2024‚Äù, ‚Äúrising sophomore‚Äù, ‚Äúsenior‚Äù, etc., 
  and your goal would be to translate them all into four categories: 2022, 2023, 2024, 2025</li>
    </ul>
  </li>
  <li>Manually splitting up data into categories or sorting data.</li>
  <li>Removing unnecessary data.</li>
  <li>Changing file formats to fit technical requirements.</li>
</ul>

<p>This is also sometimes called ‚Äúdata munging‚Äù, and is often the longest
part of the research process. Usually when drawing data from an API, however, 
we can expect data to follow strict guidelines. We‚Äôll be focusing on removing 
unnecessary data and changing Twitter data from the JSON we receive to a CSV
that we can open in Excel or Google Sheets. Shifting Twitter data from JSON to
CSV can turn a gigabyte of data into a megabyte of useful data (a 1000-fold) 
difference.</p>

<h2 id="turn-json-into-csv">Turn JSON into CSV</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import relevant dictionaries
</span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># load JSON from website
</span><span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/kmcelwee/fsi-web-scraping-seminar/main/data/dog_feelings-tweets.json'</span><span class="p">)</span>
<span class="n">all_tweets</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="p">.</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Cycle through the tweets in that JSON and collect the information we care about
</span><span class="n">csv_dict</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">all_tweets</span><span class="p">:</span>
  <span class="n">csv_dict</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
      <span class="s">'timestamp'</span><span class="p">:</span> <span class="n">tweet</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">],</span>
      <span class="s">'id'</span><span class="p">:</span> <span class="n">tweet</span><span class="p">[</span><span class="s">'id'</span><span class="p">],</span>
      <span class="s">'text'</span><span class="p">:</span> <span class="n">tweet</span><span class="p">[</span><span class="s">'full_text'</span><span class="p">],</span>
      <span class="s">'favorite_count'</span><span class="p">:</span> <span class="n">tweet</span><span class="p">[</span><span class="s">'favorite_count'</span><span class="p">],</span>
      <span class="s">'retweet_count'</span><span class="p">:</span> <span class="n">tweet</span><span class="p">[</span><span class="s">'retweet_count'</span><span class="p">],</span>
      <span class="s">'hashtags'</span><span class="p">:</span> <span class="s">';'</span><span class="p">.</span><span class="n">join</span><span class="p">([</span><span class="n">h</span><span class="p">[</span><span class="s">'text'</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">[</span><span class="s">'entities'</span><span class="p">][</span><span class="s">'hashtags'</span><span class="p">]])</span>
  <span class="p">})</span>

<span class="c1"># Turn that list of dictionaries into a dataframe and save as a CSV
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">csv_dict</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'dog_feelings-tweets.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>Here is a script that turns the JSON gathered from @dog_feelings tweets and turns it 
into a CSV with the most basic features like <code class="language-plaintext highlighter-rouge">timestamp</code> and <code class="language-plaintext highlighter-rouge">favorite_count</code>. A
good way to build a CSV is to create a list of dictionaries, as shown above. This
would look something like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
    {
      'timestamp': 'Wed May 10 03:16:19 +0000 2017',
      'id': 862144241782444038,
      'text': "good. night. don't let. the bed bugs. bamboozle",
      'favorite_count': 1856,
      'retweet_count': 376,
      'hashtags': ''
    },
    {
      'timestamp': 'Wed May 10 00:44:59 +0000 2017',  
      'id': 862106154519977984,
      'text': 'a thing. to remember: good things. are good. BUT. bad things. are not good. i think',
      'favorite_count': 1562,
      'retweet_count': 291,
      'hashtags': ''
    }
    ...
]
</code></pre></div></div>

<p>This would create the following data frame:</p>

<table>
  <thead>
    <tr>
      <th>timestamp</th>
      <th>id</th>
      <th>text</th>
      <th>favorite_count</th>
      <th>retweet_count</th>
      <th>hashtags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Wed May 10 03:16:19 +0000 2017</td>
      <td>862144241782444038</td>
      <td>good. night. don‚Äôt let. the bed bugs. bamboozle</td>
      <td>1856</td>
      <td>376</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Wed May 10 00:44:59 +0000 2017</td>
      <td>862106154519977984</td>
      <td>a thing. to remember: good things. are good. BUT. bad things. are not good. i think</td>
      <td>1562</td>
      <td>291</td>
      <td>¬†</td>
    </tr>
  </tbody>
</table>

<p>Notice that each dictionary has the same keys. These are the column names. And
then the associated value with each key is that column‚Äôs value for the given row.
Getting your head around this structure is fundamental, so if you don‚Äôt fully 
understand, make sure to not just skim over this.</p>

<p>The code above can be readily reused, as long as you can properly find the path
to the tweet information that you need.</p>

<h2 id="data-validation">Data validation</h2>

<p>Data validation is an important part of data cleaning, but it can get complicated.
Fundamentally, you want to make sure that the assumptions that you have about your
data set are actually true. The Twitter API is very consistent, so you shouldn‚Äôt
encounter too many problems, but consider using 
<a href="https://stackoverflow.com/questions/5142418/what-is-the-use-of-assert-in-python">python‚Äôs <code class="language-plaintext highlighter-rouge">assert</code> statement</a>)
to double check your assumptions about how the data is structured.</p>

<p><a href="https://cdh.princeton.edu/updates/2021/03/19/mistakes-avoid-when-using-twitter-data-first-time/">I‚Äôve outlined some hurdles</a>
I encountered when working with Twitter data and how I checked for them, but 
chances are, you won‚Äôt encounter most of them if you keep to small data sets.</p>

<h2 id="case-study-1-mtv-internship">Case Study 1: MTV Internship</h2>

<p>You‚Äôre an intern at MTV and your boss wants to know if
musicians active on Twitter get paid more money than those who aren‚Äôt active on
Twitter.</p>

<p>üé§ <strong>What are some questions we should ask before pursuing this project?</strong></p>

<details>
    <summary><a class="btn btn-green">View examples</a></summary>
<ul>
<li>How will we consider artists that aren't on Twitter?</li>
<li>How will I get a financial data for all the artists?</li>
<li>Are different genders equally likely to be on Twitter? And what are the gender pay
    disparities in the music industry?</li>
<li>How do we define "active on Twitter"? One tweet a week? A month?</li>
<li>We'll have to manually relate artists to their Twitter accounts. How long will
    that take?</li>
<li>How might outliers distort our calculation? The entertainment industry follows
    the power law, meaning a small number of people make a majority of the money.
    If Beyonce, who doesn't tweet as much, commands 10x the money of Cardi B who 
    tweets a lot, how that one data point skew our numbers?</li>
</ul>
</details>

<h2 id="tips">Tips</h2>

<ul>
  <li>Data work is both unfulfilling and time consuming. Have a clear research question
  in mind before pursuing</li>
  <li>Manually sorting data takes up more time than you think! Always run the calculations
  and weigh whether the research question you want to answer is worth the 
  time that you will invest.</li>
</ul>
